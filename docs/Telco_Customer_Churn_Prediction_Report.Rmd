---
title: "Telco Customer Churn Prediction Report"
author: "Adam Morphy, Anupriya Srivastava, Jordan Casoli,Zihan Zhou"
date: "10/12/2021"
always_allow_html: true
output: 
  html_document:
    toc: true
bibliography: references_Telco_Customer_Churn_Prediction.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
```

# Summary

In this project, we examined the following question: Can we construct a machine learning model which predicts telecommunications customer churn likelihood given obtainable customer characteristics? Further, we identified what characteristics are most important in predicting this churn risk. We used a logistic regression algorithm to build a classification model to predict which customers are likely to churn from their telecommunications company. On test data our model had satisfactory performance. With consideration to the "Churn" class, our model had an f1 score of \~0.63, a recall score of \~0.82, and a precision score of 0.51. Even though our model had a pretty good recall score, it needs more optimization before it would be ready to deploy, as our precision score was too low to be practical. The features most positively correlated with Churn include high monthly charges, month to month contracts, and fiber optic internet service. The features most negatively correlated with Churn include tenure, two year contracts, and DSL internet service.

# Introduction

Customer churn risk, the risk of customers switching to another company, is considered one of the most significant threats to the revenue of telecommunication companies. (@pustokhina2021multi) The average churn rate in the telecom industry is approximately 2.2% per month, which translates to discontinued service for one in fifty subscribers of a given company.(@team_2020) Churn is defined as whether or not a particular customer has left the company, with true representing a customer that has left, and false representing a customer that still maintains service with the company. Moreover, it is known that the cost of acquiring new customers is significantly higher than the cost of retaining them. (@pustokhina2021multi) Thus, it is clear that reducing churn risk and increasing customer retention rate is a key strategic challenge in the telecommunication industry. 

In our project, we are identifying a predictive classification model that can provide insights into which customers (based on their traits) are at higher risk of churning. Answering this question has important practical managerial implications for telecommunication companies because it is a crucial step in understanding how to reduce this risk and thus create higher customer lifetime value. Further, this predictive tool will be considered a contribution to the modern telecommunication customer relationship management systems.

# Methods

## Data

The dataset we are using comes from the public IBM github page, and is made available as part of an effort by IBM to teach the public how to use some of their machine learning tools. Unfortunately no mention is made of exactly how the data was collected, or who was responsible for the collection. Here is a link to the [mini-course](https://developer.ibm.com/patterns/predict-customer-churn-using-watson-studio-and-jupyter-notebooks/) that references the dataset we are using. The raw data is [here](https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv), and lives inside the data folder of the [public repository](https://github.com/IBM/telco-customer-churn-on-icp4d) for the mini-course. Each row in the dataset corresponds to a single customer. There are 19 feature columns, along with the target column, "churn".

## Data Cleaning and Preprocessing

Various cleaning transformations have been made to the raw data frame. Note that we are applying feature engineering transformations inside the training analysis script, instead of applying the transformations on the entire raw data set. This will avoid validating the model on pre processed data, since this would cause the training fold to be transformed relative to the validation fold, which can cause information to leak from the validation fold in to the training folds. By applying the transformation pipeline in the analysis script, we are avoiding training bias and improve generalization of the final model.

First, `TotalCharges` feature has been converted into float64 datatype. Null values in this feature are encoded as blank spaces, we we first replace the spaces with `None` values, and then covert the entire feature to a float. To improve consistency of the data frame, we are also converting the `SeniorCitizen` feature into Strings "Yes" and "No" instead of 1 and 0, which will match how the other categories are encoded. Finally, we are splitting the data frame into training and testing splits, with 30% of the data (2113 observations) being left as the cleaned testing set.

We are also dropping `gender` from the data frame due to ethical limitations of discriminating on gender for what makes customers likely to leave the company. `CustomerID` is dropped from the data as well, since it is not useful for prediction.

## Analysis

As mentioned in the above section, we did preliminary data cleaning, data wrangling, and data splitting in the pre-processing section. This was done to ensure that we do conduct any analysis on the test data. 

We did exploratory data analysis (EDA) on the training data to get a preliminary understanding of the input features. We first looked at the distribution of target (`Churn`) class to understand class imbalanced. From the plot below, it is clear that there is imbalance in the target variable as about 75% observations below to the negative class (Churn = "False"). To handle class imbalance, we will use `precision`, `recall` and `f1` score as the model performance evaluation metric instead of the default `accuracy` metric. We used a logistic regression algorithm to build a classification model to predict which customers are likely to churn from their telecommunications company.

```{r class imbalance, echo=FALSE, fig.cap = "Figure 1: Distribution of response variable shows class imbalance", out.width = '40%', fig.align="center"}
knitr::include_graphics("../results/figure_1_class_imbalance.png")
```

We then segregated the features as numerical and categorical exploratory variables. The input data has 3 numerical and 12 categorical features.

For numerical variables, we looked into the distribution of these features for the two target classes. It was observed that `Tenure` shows split between the two target classes, where as the other two features `Monthly Charges` and `Total Charges` do not provide a clear bifurcation between th two classes. Hence, `Tenure` feature seems to be important where as `Monthly Charges` and `Total Charges` do not look too important.

```{r numerical features distribution, echo=FALSE, fig.cap = "Figure 2: Distribution of numerical features for response variable indicates that Tenure may be important for prediction", out.width = '100%', fig.align="center"}
knitr::include_graphics("../results/figure_2_numeric_feat_dist.png")
```

We also analyzed the correlation between the three numerical features. Here, it was observed that there is high positive correlation between `Tenure` and `Total Charges`. The correlation between numeric features is an important consideration while interpreting the model. In case, any two features are highly correlated, we may have to merge them together or drop one of them to improve model performance. This correlation is represented using a heat-map, which gives correlation values and color codes.

```{r numerical features correlation, echo=FALSE, fig.cap = "Figure 3: Correlation chart for numerical features shows high correlation between input variables, Tenure and Total_charges", out.width = '60%', fig.align="center"}
knitr::include_graphics("../results/figure_3_numeric_feat_corr.png")
```

We further analysed the significance of categorical features in predicting the target class. A list of all categorical features along with the possible class values is given below for reference:

```{r categorical features summary, echo=FALSE, fig.cap = "Table 1: Categorical Features Summary", out.width = '60%', fig.align="center"}
knitr::include_graphics("../results/table_1_cat_unique_values.png")
```

We observed the distribution of categorical features pertaining to demographics. From the bar charts, we can pick out the categories which have a higher ratio of positive class (Churn="True"). It can be observed that people with no dependents, no partner and senior citizens had a higher Churn.

```{r categorical demographic features, echo=FALSE, fig.cap = "Figure 4: Distribution of response variable for demographic features indicates Partner(Y/N) may be important for prediction", out.width = '40%', fig.align="center"}
knitr::include_graphics("../results/figure_4_cat_feat_churn_dist.png")
```

We further observed the distribution of categorical features pertaining to Telecom Company services. For this, we used 2D histograms. In these plots, we observed the categories for which there were higher number of positive classes (Churn = "True"). It was noted that for various features, the following categories have higher Churn rate: Internet Service (Fiber Optic service), Contract (Monthly), Online Security (No), Online Backup (No), Payment Method (Electronic Check), Paperless Billing (Yes), Tech Support (No), Device Protection (No). It was also noted the for the following features, customer churn was equally distributed across all categories: Multiple Lines, Streaming Movies, Streaming TV.

```{r categorical service features, echo=FALSE, fig.cap = "Figure 5: 2D histogram showing distribution of response variables across Categories", out.width = '60%', fig.align="center"}
knitr::include_graphics("../results/figure_5_cat_feat_2dhist.png")
```

We used a logistic regression algorithm to build a classification model to predict which customers are likely to churn from their telecommunications company. Additionally, we reported which features are most positively & negatively correlated with our target, as learned by our model. We used the Python language[@Python] and the following Python packages were used to perform this analysis: docopt [@docopt], os [@Python], scikit-learn [@scikit-learn], Pandas [@reback2020pandas], Numpy Array[@2020NumPy-Array], matplotlib [@hunter2007matplotlib]and altair [@vanderplas2018altair]. We used the R language[@R] and the following R packages were used to perform this analysis: knitr [@knitr], tidyverse [@tidyverse]. Our code for the analysis and our related resources and progress reports can be found here: (<https://github.com/UBC-MDS/Telco_Customer_Churn_Prediction_Group12>)

# Results & Discussion

We chose to use a logistic regression model, with f1 score as our primary scoring metric in order to account for our class imbalance. We decided to use a logistic regression model over other models such as `DecisionTree` or `RandomForest` primarily because of our familiarity with the algorithm, and because it is convenient to pull feature importance's from the fit model. We realized that this may not be optimal, and make note of this in our "Limitations & Future" section at the bottom of the report. To improve the performance of our model, we performed hyper parameter optimization in the form of an exhaustive grid search, with 4 cross validation folds, over hyper parameters `C` & `class_weight`. This yielded optimal parameters `C=0.01` & `class_weight="balanced"`

After training our model on our full training set, these are the features most positively correlated with Churn:

```{r positive feature importance, echo=FALSE, message=FALSE, fig.align="center"}
read_csv("../results/feature_importance.csv") |> 
  arrange(desc(Coefficient)) |> 
  head(5) |> 
  knitr::kable(caption = "Table 2: Summary of features most positively correlated with Churn") 
```

These are the features most negatively correlated with Churn:

```{r, echo=FALSE, message=FALSE, fig.align="center"}
read_csv("../results/feature_importance.csv") |> 
  arrange(Coefficient) |> 
  head(5) |> 
  knitr::kable(caption = "Table 3: Summary of features most negatively correlated with Churn") 
```

These feature importance's make sense intuitively, as customers on month-to-month contracts are much more likely to churn than customers on two year contracts. One surprising result is that customers with fibre optic internet service are much more likely to churn than customers with DSL internet service. As a result, the pricing strategy and quality fo service for the fibre optic internet service may need to be reconsidered. Higher monthly charges, electronic check payments, and no online security services were all also predictors of customers leaving the company.

Conversely, longer tenured customers are less likely to leave, along with those on a two year contract, using DSL internet service, using online security services, and those requiring tech support. In these cases, we can recommend that the company consider promoting two year service contracts, promoting online security services, as well as promote the companies tech support to solve any issues customers may have. Clearly, those who use the companies tech support are satisfied with the service and well be less likely to leave. Tech support accessibility should also be better communicated, such that customers uncderstand where to go when they need help.

On test data our model had satisfactory performance. With consideration to the "Churn" class, our model had an f1 score of \~0.63, a recall score of \~0.82, and a precision score of 0.51. Specifically, the harmonic average between the models ability to correctly classify churn (recall), and the models ability to avoid false positives (precision) is ~0.63 on the testing set.

```{r, echo=FALSE, message=FALSE, fig.align="center"}
classification_report_df <- read_csv("../results/classification_report.csv")

classification_report_df |> knitr::kable(caption = "Table 4: Classification Report on Test Data.")
```

Given the business problem that our prediction algorithm is trying to solve, it was more important for us to be able to identify the Churn class correctly (to minimize false negatives). This is because it is very costly for company to loose customers and attract new ones, and much less costly to keep them. Therefore we want our model to make more false positives than false negatives, in order to avoid the cost of miss classifying a leaving customer. As evidenced by the confusion matrix below, our model made 413 false positives and only 97 false negatives:

```{r confusion matrix, echo=FALSE, message=FALSE, fig.cap = "Figure 6: Confusion Matrix shows low number of False Negatives", out.width = '60%', fig.align="center"}
knitr::include_graphics("../results/confusion_matrix.png")
```

While we are happy with the recall score of \~0.82, the lack of precision in our model means that further work should be done to optimize the model before we can recommend deploying it.

# Limitations & Future

To further improve on this model, there are a few ideas we can suggest. First, we would recommend testing different classification algorithms against the original logistic regression model to see if f1 score can be improved. The random forest classifier algorithm, along with boosting, averaging, and stacking methods could have also been tested and compared, using feature importance's and shap values from the model to understand the best features.

Second, given that some of our numerical features are highly correlated with each other, we would recommend using a feature selection algorithm (ex. recursive feature elimination (RFE)) to refine the features used in the final model. This would have the advantage of making the model more interpretable. 

It's possible that the model could be improved by choosing a better classification threshold. This could be done by plotting precision-recall curve during cross validation. Alternatively, it might make sense not to use "hard" predictions, and to instead use `predict_proba` to provide churn probabilities for each customer.

Finally, the employing such a model could come with limitations, regarding the availability of data, and the context of the given company. Given that our data was derived from a practice business case from IBM, such analysis would need to be reproduced with updated information and features of a given company. Specifically, over time, the services and offerings of a company will change, especially after implementing some of our recommendations, such as promoting tech support. New data would then certainly change the most important features to consider for customer retention, and the model should then be  adjusted and revised accordingly to ensure the current retention strategy of the company is optimal and up to date. 

Despite limitations and room future improvements, our result shows a model that can be utilized by telecommunication companies to better predict their customer's churn rate if they have information on respective customer characteristics. This model has significant downstream impact as it can help management reduce acquisition cost and increase customer retention rate.

# References
